{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Langevin algorithms for Markovian Neural Networks and Deep Stochastic control</h1>\n",
    "\n",
    "We show how to:\n",
    "<ol>\n",
    "    <li>Use Langevin optimizers and Layer Langevin optimizers for any Tensorflow model training</li>\n",
    "    <li>Use our framework for comparing differents optimizers on a same Stochastic Optimal Control problem</li>\n",
    "    <li>Use our framework to create a new Stochastic Optimal Control problem.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1) Langevin Optimizers</h2>\n",
    "\n",
    "Optimizers in the <tt>optimizers</tt> directory can be directly used as instances of the TensorFlow <tt>Optimizer</tt> base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizers.ladam import LAdam, LayerLAdam\n",
    "from optimizers.lrmsprop import LRMSprop, LayerLRMSprop\n",
    "from optimizers.ladadelta import LAdadelta, LayerLAdadelta\n",
    "\n",
    "optimizer = LAdam(learning_rate=1e-3, sigma=1e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schedules from <tt>tf.keras.optimizers.schedules</tt> may be passed to the arguments <tt>learning_rate</tt> and to <tt>sigma</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[100], values=[1e-3,1e-4])\n",
    "sigma_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[100], values=[1e-3,0.])\n",
    "\n",
    "optimizer = LAdam(learning_rate=lr_schedule, sigma=sigma_schedule)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Layer Langevin optimizers</b>\n",
    "\n",
    "The argument <tt>langevin_layers</tt> specify the layers of the model that are trained with Langevin noise.\n",
    "\n",
    "When using Layer Langevin optimizers, the function <tt>set_langevin(model)</tt> must be used after the <tt>model</tt> is compiled with this optimizer and built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizers.base import set_langevin\n",
    "\n",
    "optimizer = LayerLAdam(learning_rate=1e-3, sigma=1e-3, langevin_layers=[0,1])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "model(tf.random.normal((1,5))) # build the model\n",
    "set_langevin(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2) Running an experiment for Stochastic Optimal Control</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Builder:</b>\n",
    "\n",
    "A <tt>ModelBuilder</tt> is required for the <tt>experiment</tt>.\n",
    "We provide three different <tt>ModelBuilder</tt>s: <tt>Fishing</tt>, <tt>DeepHedging</tt>, <tt>OilDrilling</tt>. We refer to the corresponding simulation files for the instantation of each of these classes.\n",
    "\n",
    "Note that <tt>OilDrilling</tt> only works with <tt>dim=1</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fishing import Fishing\n",
    "from models.deep_hedging import DeepHedging\n",
    "from models.oil_drilling import OilDrilling\n",
    "\n",
    "dim=5; alpha=0.9\n",
    "model_builder = DeepHedging(\n",
    "    T=1., N_euler=50, dim=dim,\n",
    "    multiple_ctrls=False, ctrl_hidden_units=[32,32],\n",
    "    ell=lambda x:(1./(1.-alpha))*tf.keras.activations.relu(x),\n",
    "    a = 1.*tf.ones((dim,)), b = 0.04*tf.ones((dim,)),\n",
    "    sigma = 2.*tf.ones((dim,)), rho = -0.7*tf.ones((dim,)),\n",
    "    K = 1.*tf.ones((dim,)), T_COST=5e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dataloader:</b>\n",
    "\n",
    "Define the input (initial condition) of the Stochastic Control problem. We provide <tt>DatasetLoader</tt>s: <tt>ConstantLoader</tt>, <tt>ConstantMultipleLoader</tt>, <tt>DataLoaderFromMap</tt>. The arguments are:\n",
    "\n",
    "<ul>\n",
    "    <li><tt>N_train</tt>: number of trajectories for each epoch</li>\n",
    "    <li><tt>N_test</tt>: number of trajectories to estimate the loss with at the end of each epoch</li>\n",
    "    <li><tt>batch_size</tt></li>\n",
    "    <li><tt>X0</tt>: (only for <tt>ConstantLoader</tt>): initial condition, given as a tensorflow tensor or a numpy array</li>\n",
    "    <li><tt>X0_list</tt>: (only for <tt>ConstantMultipleLoader</tt>): list of initial conditions when the model as multiple inputs, given as a list of tensorflow tensors or numpy arrays</li>\n",
    "    <li><tt>get_X0</tt>: (only for <tt>DataLoaderFromMap</tt>): function that takes one argument as a tensorflow tensor and that returns a tensorflow tensor with same shape</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.constant import ConstantLoader, ConstantMultipleLoader\n",
    "from data.from_map import DataLoaderFromMap\n",
    "\n",
    "s0, v0 = 1., 0.1\n",
    "dataloader = ConstantMultipleLoader(\n",
    "    X0_list = [s0*tf.ones((dim,)), v0*tf.ones((dim,))],\n",
    "    N_train = 512*5,\n",
    "    N_test = 512*25,\n",
    "    batch_size = 512)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then build the <tt>experiment</tt> with additional arguments:\n",
    "<ul>\n",
    "    <li><tt>optimizers</tt>: list of tensorflow optimizers to compare</li>\n",
    "    <li><tt>base</tt>: path to save the results</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import Experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    model_builder=model_builder,\n",
    "    dataloader=dataloader,\n",
    "    EPOCHS=20,\n",
    "    optimizers=[LAdam(learning_rate=1e-3, sigma=1e-3),\n",
    "                LAdam(learning_rate=1e-3, sigma=0.)],\n",
    "    base='./')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><tt>experiment.load_data()</tt>: load the data according to the dataloader; must be used before any training</li>\n",
    "    <li><tt>experiment.run_experiment()</tt>: train the model for each optimizer</li>\n",
    "    <li><tt>experiment.plot()</tt>: plot the training curves for each optimizer</li>\n",
    "    <li><tt>experiment.plot_traj(opt_index)</tt>: plot a random trajectory (after the model is trained); <tt>opt_index</tt> is the index of the optimizer to use</li>\n",
    "    <li><tt>experiment.save_data(dir)</tt>: save the training curves as <tt>csv</tt> files in the <tt>experiment.base/dir</tt> directory (the directory is created)</li>\n",
    "    <li><tt>experiment.save_traj(dir)</tt>: save the random trajectory as a <tt>csv</tt> file in the <tt>experiment.base/dir</tt> directory (the directory is created)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.load_data()\n",
    "experiment.run_experiment()\n",
    "experiment.plot()\n",
    "\n",
    "experiment.plot_traj(opt_index=1)\n",
    "\n",
    "experiment.save_data('deep_hedging_adam')\n",
    "experiment.save_traj('deep_hedging_traj')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3) Setting custom <tt>ModelBuilder</tt>s for Stochastic Optimal Control</h2>\n",
    "\n",
    "A new <tt>ModelBuilder</tt> must be implemented as a subclass of <tt>models.base.ModelBuilder</tt> and must have a method <tt>getModel(self)</tt> which returns a Tensorflow model. The output of the model must be the (scalar) loss <tt>J</tt> of shape <tt>[batch_size, 1]</tt> or <tt>[batch_size, R]</tt> where the <tt>R-1</tt> last entries will be only used for plotting purposes in <tt>experiment.plot_traj</tt>.\n",
    "\n",
    "We refer to the source files <tt>models.fishing</tt>, <tt>models.deep_hedging</tt>, <tt>models.oil_drilling</tt>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "755bca588c5ad61560da42c0cec298747f8b74f9b58b010e18f102b95c79ceda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
